# ğŸ™ï¸ Real-Time Voice Assistant with Deepgram + OpenAI ğŸ§ ğŸ”Š

A real-time conversational voice assistant using **Deepgram** for speech-to-text ğŸ—£ï¸â¡ï¸ğŸ“ and **OpenAI GPT-3.5 Turbo** for intelligent responses ğŸ“â¡ï¸ğŸ§  â€” powered by **Python** and **asyncio** for non-blocking performance ğŸš€.

---

## ğŸ“¦ Features

âœ… Live microphone input and transcription  
âœ… Seamless integration with OpenAI's GPT model  
âœ… Real-time Text-to-Speech (TTS) responses  
âœ… Multi-tasking with `asyncio`  
âœ… Modular design for easy maintenance and scaling  

---

## ğŸ§  LLMHandler: Core Class

> Located in: `llm_handler.py`  
A class for handling interaction with OpenAI's language model.

### Key Methods
- `add_user_message(message)` â• Add user input  
- `get_llm_response()` ğŸ§  Get assistantâ€™s response  
- `clear_history()` ğŸ§½ Reset conversation (keep system prompt)

---

## ğŸ§° Main App Logic

> Located in: `main.py`  
Handles:
- ğŸ¤ Audio capture using `pyaudio`
- ğŸŒ WebSocket streaming to Deepgram
- ğŸ§  LLM interaction and ğŸ’¬ response
- ğŸ”Š Speaking the assistant's response back

---

## ğŸ› ï¸ Installation & Setup

1. ğŸ” Clone the repo
```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```
ğŸ§ª Create a .env File with Your API Keys
```
DEEPGRAM_API_KEY=your_deepgram_key_here
OPENAI_API_KEY=your_openai_key_here
```
ğŸ§© Project Structure
```
ğŸ“ your-project/
â”œâ”€â”€ main.py                # Main program for managing audio stream and logic
â”œâ”€â”€ llm_handler.py         # GPT conversation handler class
â”œâ”€â”€ speak.py               # (Assumed) Text-to-speech helper
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ .env                   # API keys (not committed)
```
